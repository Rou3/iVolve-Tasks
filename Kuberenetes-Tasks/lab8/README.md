# Lab 17: Pod Resource Management with CPU and Memory Requests & Limits

## ğŸ“Œ Objective

The goal of this lab is to practice **Pod Resource Management** in Kubernetes by configuring **CPU and Memory requests and limits** for a Deployment and verifying them at runtime.

---

## ğŸ› ï¸ Lab Requirements

Update an existing Deployment to:

### Resource Requests

* **CPU:** 0.5 vCPU
* **Memory:** 1Gi

### Resource Limits

* **CPU:** 1 vCPUs
* **Memory:** 2Gi

### Verification

* Use `kubectl describe pod` to verify requests and limits
* Use `kubectl top pod` to monitor real-time resource usage

---

## ğŸ“‚ Files Used

* `nodejs-deployment.yaml`

---

## ğŸ“„ Deployment YAML

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodejs-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nodejs
  template:
    metadata:
      labels:
        app: nodejs
    spec:
      tolerations:
      - key: "node"
        operator: "Equal"
        value: "worker"
        effect: "NoSchedule"
      containers:
      - name: alpine
        image: alpine:latest
        command: ["sh", "-c", "sleep 3600"]
        resources:
          requests:
            cpu: "0.5"
            memory: 1Gi
          limits:
            cpu: "1"
            memory: 2Gi
```

---

## â–¶ï¸ Steps to Run

### 1ï¸âƒ£ Apply the Deployment

```bash
kubectl apply -f nodejs-deployment.yaml
```
---

### 2ï¸âƒ£ Verify Pod Status

```bash
kubectl get pods
```

Expected output:

```text
nodejs-app-xxxxx   1/1   Running
```

---

### 3ï¸âƒ£ Verify Resource Requests & Limits

```bash
kubectl describe pod <POD_NAME>
```

Look for:

```text
Requests:
  cpu:     0.5
  memory:  1Gi
Limits:
  cpu:     1
  memory:  2Gi
```

---

### 4ï¸âƒ£ Monitor Resource Usage

> Metrics Server must be enabled

```bash
kubectl top pod
```

Sample output:

```text
NAME           CPU(cores)   MEMORY(bytes)
nodejs-app     10m          30Mi
```

---

## ğŸ§  Key Concepts

* **Requests** define the minimum resources required by a Pod
* **Limits** define the maximum resources a Pod can consume
* If requests exceed node capacity, the Pod remains in `Pending` state
* CPU limits cause throttling, memory limits may cause OOMKill

---

## âœ… Lab Status

âœ” Deployment created successfully
âœ” Resource requests and limits applied
âœ” Resources verified using `kubectl describe`
âœ” Usage monitored using `kubectl top`

---

## âœ¨ Notes

* `replicas` set to **1** to avoid insufficient CPU issues in Minikube
* `tolerations` added to allow scheduling on tainted worker nodes

---
